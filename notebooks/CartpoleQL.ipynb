{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a3fe6-b8cd-4e5c-b661-9e42087cbe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "import io\n",
    "import base64\n",
    "from IPython import display as ipythondisplay\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from src.utils import utils\n",
    "from src.utils.kbins_discretizator import KBinsDiscretizator\n",
    "from src.agents.q_agent import QAgent\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b87ed6-8d76-47c2-816c-d56386c7e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "N_EPISODES = 5000\n",
    "N_STEPS = 1000\n",
    "\n",
    "# AGENT HYPERPARAMETERS\n",
    "EXPLORATION_RATIO = 1.0\n",
    "LEARNING_RATE = 0.2\n",
    "DISCOUNT_FACTOR = 0.9\n",
    "E_DECAY_LIMIT = 0.05\n",
    "E_DECAY_RATE = 0.001\n",
    "\n",
    "# CONTINOUS ACTIONS BINS\n",
    "BINS_1 = 10\n",
    "BINS_2 = 10\n",
    "BINS_3 = 10\n",
    "BINS_4 = 10\n",
    "\n",
    "# MISC\n",
    "RENDER = False\n",
    "REPORT_FILE = False\n",
    "STEPS_REPORT = 100\n",
    "\n",
    "config = {\n",
    "    \"n_episodes\": N_EPISODES,\n",
    "    \"n_steps\": N_STEPS,\n",
    "    \"exploration_ratio\": EXPLORATION_RATIO,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"discount_factor\": DISCOUNT_FACTOR,\n",
    "    \"e_decay_limit\": E_DECAY_LIMIT,\n",
    "    \"e_decay_rate\": E_DECAY_RATE,\n",
    "    \"bin_1\": BINS_1,\n",
    "    \"bin_2\": BINS_2,\n",
    "    \"bin_3\": BINS_3,\n",
    "    \"bin_4\": BINS_4,\n",
    "    \"render\": RENDER,\n",
    "    \"report_file\": REPORT_FILE\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0b791-3ad6-407b-9d16-ecb7e5658a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# TODO: Tengo que ver cuales son los nombres de las acciones\n",
    "actions_dict = {0: 'Zero', 1: 'One'}\n",
    "hist = []\n",
    "\n",
    "discretizator = KBinsDiscretizator(env.observation_space.low, env.observation_space.high, bins_array=[BINS_1, BINS_2, BINS_3, BINS_4], encode='ordinal', strategy='uniform')\n",
    "\n",
    "agent = QAgent(discretizator.get_n_states(), env.action_space, exploration_ratio=EXPLORATION_RATIO,\n",
    "               learning_rate=LEARNING_RATE, discount_factor=DISCOUNT_FACTOR, e_decay_limit=E_DECAY_LIMIT, e_decay_rate=E_DECAY_RATE)\n",
    "\n",
    "print('Obervation Space:', env.observation_space)\n",
    "print('Observation Space low:', env.observation_space.low)\n",
    "print('Observation Space high:', env.observation_space.high)\n",
    "print('Observation Space shape:', env.observation_space.shape)\n",
    "print('Action Space:', env.action_space)\n",
    "print('Action Space n:', env.action_space.n)\n",
    "print('Reward Range:', env.reward_range)\n",
    "print(env.metadata)\n",
    "print(env.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db2152-fac6-484c-8d35-92e33573bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n############### Ini Training ###############\\n\")\n",
    "for i_episode in range(N_EPISODES):\n",
    "    state = env.reset()\n",
    "    reward_counter = 0\n",
    "    if RENDER:\n",
    "        print(\"############### Ini Episode\", i_episode, \"###############\")\n",
    "    for t in range(N_STEPS):\n",
    "        if RENDER:\n",
    "            env.render()\n",
    "            print(\"Actual State:\", state)\n",
    "        action = agent.get_next_step(discretizator.idx_state(state))\n",
    "        if RENDER:\n",
    "            print(\"Action:\", actions_dict[action])\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        reward_counter += reward\n",
    "        if RENDER:\n",
    "            print(\"Next State:\", next_state, \"\\n\")\n",
    "        agent.update_qtable(discretizator.idx_state(state), action, reward, discretizator.idx_state(next_state), done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    agent.greedy_decay()\n",
    "    if i_episode % STEPS_REPORT == 0 and i_episode != 0:\n",
    "        mean_reward_last_episodes = np.mean([ episode['reward'] for episode in hist[-STEPS_REPORT:] ])\n",
    "        mean_steps_last_episodes = np.mean([ episode['steps'] for episode in hist[-STEPS_REPORT:] ])\n",
    "        print('Episode: {}\\t\\tMeanReward: {}\\t\\tMeanSteps: {}\\t\\tEpsilon: {:.2f}\\t\\tInfo: {}'.format(i_episode, int(mean_reward_last_episodes), int(mean_steps_last_episodes), agent.exploration_ratio, info))\n",
    "    hist.append({'reward': reward_counter, 'steps': t+1})\n",
    "    if RENDER:\n",
    "        print(\"############### End Episode\", i_episode, \"###############\")\n",
    "print(\"\\n############### End Training ###############\\n\")\n",
    "print(\"\\n\\n################## Report ##################\\n\")\n",
    "report = {\"average_reward\": utils.get_average_reward_last_n(hist, N_EPISODES),\n",
    "            \"average_reward_last_10\": utils.get_average_reward_last_n(hist, int(N_EPISODES*0.1)),\n",
    "            \"average_steps\": utils.get_average_steps_last_n(hist, N_EPISODES),\n",
    "            \"average_steps_last_10\": utils.get_average_steps_last_n(hist, int(N_EPISODES*0.1))\n",
    "            }\n",
    "print(\"Average reward:\", report[\"average_reward\"])\n",
    "print(\"Average reward of last 10%(\"+str(int(N_EPISODES*0.1))+\"):\",report[\"average_reward_last_10\"])\n",
    "print(\"Average steps:\", report[\"average_steps\"])\n",
    "print(\"Average steps of last 10%(\"+str(int(N_EPISODES*0.1))+\"):\",report[\"average_steps_last_10\"])\n",
    "print(\"\\n################ End Report ################\")\n",
    "if REPORT_FILE:\n",
    "    utils.generate_report_file(config, report, hist, agent.qtable)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99da45d-edbf-40ae-949b-acbe9018d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video():\n",
    "  mp4list = glob.glob('resources/videos/cartpole/*.mp4')\n",
    "  if len(mp4list) > 0:\n",
    "    mp4 = mp4list[0]\n",
    "    video = io.open(mp4, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "  else: \n",
    "    print(\"Video not found\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "  env = wrappers.Monitor(env, './resources/videos/cartpole', force=True)\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717c06d-017a-4262-96d8-924228320487",
   "metadata": {},
   "outputs": [],
   "source": [
    "clever_agent = QAgent(discretizator.get_n_states(), env.action_space, qtable=agent.get_qtable(), exploration_ratio=0,\n",
    "               learning_rate=0, discount_factor=0, e_decay_limit=0, e_decay_rate=0)\n",
    "\n",
    "env = wrap_env(gym.make('CartPole-v1'))\n",
    "state = env.reset()\n",
    "done = False\n",
    "ep_rew = 0\n",
    "while not done:\n",
    "  env.render()\n",
    "  action = agent.get_next_step(discretizator.idx_state(state))\n",
    "  state, reward, done, info = env.step(action)\n",
    "  ep_rew += reward\n",
    "print('Episode reward was {}'.format(ep_rew))\n",
    "env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6374d-2332-441a-b786-92a1d4c3dafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
